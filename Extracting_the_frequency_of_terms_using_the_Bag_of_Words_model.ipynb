{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "def vectorize(tokens):\n",
        "  '''This function takes 11st of words in a sentence as input.\n",
        "  and returns a vector of size of filtered vocab. It puts if the\n",
        "  word is not present in tokens and count of token if present.'''\n",
        "\n",
        "  vector=[] \n",
        "  for w in filtered_vocab:\n",
        "    vector.append(tokens.count(w)) \n",
        "  return vector\n",
        "\n",
        "def unique (sequence):\n",
        "  '''This functions returns a list in which the order remains sane and no iten repeats. Using the set() function does not\n",
        "  preserve the original ondering, so I font use that instead'''\n",
        "  seen = set() \n",
        "  return [x for x in sequence if not (x in seen or seen.add(x))]\n",
        "\n",
        "#create a List of stopwards. You can taport stopwords from th too\n",
        "stopwords=[\"to\",\"is\",\"a\"] \n",
        "\n",
        "#List of special characters. You can use regular expressions too\n",
        "special_char=[\",\",\":\",\" \",\";\",\".\",\"?\"]\n",
        "\n",
        "#Write the sentences in the corpus, in our case, just two\n",
        "string1 = \"welcome to Great Learning Now start learning\"\n",
        "string2 = \"Learning is a good practice\"\n",
        "\n",
        "#convert them to lower case \n",
        "string1=string1.lower()\n",
        "string2=string2.lower()\n",
        "\n",
        "#split the sentences into tabens\n",
        "tokens1=string1.split()\n",
        "tokens2=string2.split() \n",
        "print(tokens1)\n",
        "print(tokens2)\n",
        "\n",
        "#create a vocabulary tat\n",
        "vocab=unique(tokens1+tokens2)\n",
        "print(vocab)\n",
        "\n",
        "#filter the vocabulary list \n",
        "filtered_vocab=[]\n",
        "for w in vocab:\n",
        "  if w not in stopwords and w not in special_char:\n",
        "    filtered_vocab.append(w)\n",
        "print(filtered_vocab) \n",
        "\n",
        "#convert sentences into vectords\n",
        "vector1=vectorize(tokens1)\n",
        "print(vector1) \n",
        "vector2=vectorize(tokens2)\n",
        "print(vector2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biUNURg24oEs",
        "outputId": "c0275d9d-3013-4124-9de8-8a472b49b5df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['welcome', 'to', 'great', 'learning', 'now', 'start', 'learning']\n",
            "['learning', 'is', 'a', 'good', 'practice']\n",
            "['welcome', 'to', 'great', 'learning', 'now', 'start', 'is', 'a', 'good', 'practice']\n",
            "['welcome', 'great', 'learning', 'now', 'start', 'good', 'practice']\n",
            "[1, 1, 2, 1, 1, 0, 0]\n",
            "[0, 0, 1, 0, 0, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a Boy of Words Modec with selearn"
      ],
      "metadata": {
        "id": "wsp1wih1r1tq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "sentence_1=\"This is a good job.? will not miss it for anything\" \n",
        "sentence_2=\"This is not good at all\"\n",
        "\n",
        "CountVec = CountVectorizer(ngram_range=(1,1), #to use bigrams ngrom_range=(2,2)\n",
        "                           stop_words='english')\n",
        "\n",
        "#transform\n",
        "Count_data = CountVec.fit_transform([sentence_1, sentence_2])\n",
        "\n",
        "#create dataframe\n",
        "cv_dataframe=pd.DataFrame(Count_data.toarray(),columns=CountVec.get_feature_names())\n",
        "print(cv_dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y42MRFz0wsUu",
        "outputId": "71ac0e41-d6c8-41cf-e28b-e9d0bd474814"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   good  job  miss\n",
            "0     1    1     1\n",
            "1     1    0     0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    }
  ]
}